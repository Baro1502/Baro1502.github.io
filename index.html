<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- , shrink-to-fit=no -->
        <title>Tran Nguyen Duy Bao - AI and ML Engineer | Portfolio</title>
        <meta name="description" content="Portfolio of Tran Nguyen Duy Bao, AI and ML Engineer specializing in Machine Learning, Data Science, and Large Language Models (LLMs) at Ho Chi Minh city, Vietnam.">
        <meta name="keywords" content="Tran Nguyen Duy Bao, AI Engineer, Machine Learning Expert, Data Science Specialist, LLMs Researcher, Artificial Intelligence Portfolio">
        <link rel="stylesheet" type="text/css" href="styles/main.css">
        <link rel="stylesheet" type="text/css" href="styles/nav.css">
        <link rel="stylesheet" type="text/css" href="styles/info.css">
        <link rel="stylesheet" type="text/css" href="styles/about.css">
        <link rel="stylesheet" type="text/css" href="styles/timeline.css">
        <link rel="stylesheet" type="text/css" href="styles/projects.css">
        <link rel="stylesheet" type="text/css" href="styles/publications.css">
        <!-- <link rel="stylesheet" type="text/css" href="styles/blog.css"> -->

         <!-- Favicon -->
        <link rel="icon" href="assets/logo.jpeg" type="image/x-icon">

        <!-- Open Graph tags -->
        <meta property="og:title" content="Tran Nguyen Duy Bao | AI and ML Engineer">
        <meta property="og:description" content="Portfolio of Tran Nguyen Duy Bao, AI and ML Engineer, specializing in Machine Learning, Data Science, and LLMs.">
        <meta property="og:image" content="https://github.com/Baro1502/portfolio/blob/main/assets/me.jpg" />
        <meta property="og:url" content="https://https://nikhil-paleti.github.io/" />
        <meta property="og:type" content="website" />

            <!-- Twitter Card tags -->
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:creator" content="@nikhil2362">

        <!-- Structured Data Markup -->
    <script type="application/ld+json">
        {
          "@context": "https://schema.org",
          "@type": "Person",
          "name": "Tran Nguyen Duy Bao",
          "url": "https://nikhil-paleti.github.io/",
          "image": "https://nikhil-paleti.github.io/assets/me.jpg",
          "sameAs": [
            "https://www.linkedin.com/in/bao-tran-nguyen-duy/",
            "https://github.com/Baro1502",
          ],
          "jobTitle": "AI and ML Engineer",
          "alumniOf": {
            "@type": "CollegeOrUniversity",
            "name": "Amrita Vishwa Vidyapeetham"
          },
          "affiliation": {
            "@type": "CollegeOrUniversity",
            "name": "University of California San Diego"
          },
          "knowsAbout": ["Machine Learning", "Data Science", "Large Language Models"],
          "description": "Tran Nguyen Duy Bao is a graduate student at UC San Diego, specializing in Machine Learning, Data Science, and Large Language Models (LLMs)."
        }
        </script>
    </head>
    <body>
        <header class="gradient-background">
            <nav>
                <div class="nav-left">
                    <a href="#dhead" class="nav-link">Tran Nguyen Duy Bao</a>
                </div>
                <div class="nav-right">
                    <a href="#about" class="nav-link">About</a>
                    <!-- <a href="#blog" class="nav-link">Blog</a> -->
                    <a href="#projects" class="nav-link">Projects</a>
                    <!-- <a href="#publications" class="nav-link">Publications</a> -->
                    <a href="#timeline" class="nav-link">Timeline</a>
                </div>
                <div class="nav-mobile">
                    <!-- <button id="menu-toggle">Menu</button> -->
                    <button id="menu-toggle" aria-label="Toggle menu">
                        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                            <path d="M4 6H20M4 12H20M4 18H20" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                        </svg>
                    </button>
                    <div id="mobile-menu">
                        <a href="#about" class="nav-link">About</a>
                        <!-- <a href="#blog" class="nav-link">Blog</a> -->
                        <a href="#projects" class="nav-link">Projects</a>
                        <!-- <a href="#publications" class="nav-link">Publications</a> -->
                        <a href="#timeline" class="nav-link">Timeline</a>
                    </div>
                </div>
            </nav>
        </header>

        <main>
            <div id="dhead" class="container gradient-background">
                <div class="row">
                    <div id="dpic">
                        <img src="assets/me.jpg" alt="Tran Nguyen Duy Bao - AI and ML Engineer" />
                    </div>
                    <div id="ddesc">
                        <h1>Tran Nguyen Duy Bao</h1>
                        <h2>Exploring the Frontiers of AI and Data Science</h2>
                        <div id="dico">
                            <a href="https://www.linkedin.com/in/bao-tran-nguyen-duy/" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn"><img src="https://cdn.jsdelivr.net/npm/simple-icons@v5/icons/linkedin.svg" class="iico" alt="Connect with Nikhil on LinkedIn"/></a>
                            <a href="https://github.com/Baro1502" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><img src="https://cdn.jsdelivr.net/npm/simple-icons@v5/icons/github.svg" class="iico" alt="View Nikhil's GitHub projects"/></a>
                            <!-- <a href="https://scholar.google.co.uk/citations?user=RuldEOQAAAAJ&hl=en" target="_blank" rel="noopener noreferrer" aria-label="Google Scholar"><img src="https://cdn.jsdelivr.net/npm/simple-icons@v5/icons/googlescholar.svg" class="iico" alt="Nikhil's Google Scholar profile"/></a> -->
                            <!-- <a href="https://x.com/nikhil2362" target="_blank" rel="noopener noreferrer" aria-label="Twitter"><img src="https://cdn.jsdelivr.net/npm/simple-icons@3.13.0/icons/twitter.svg" class="iico" alt="Follow Nikhil on X (Twitter)" /></a> -->
                            <img src="https://cdn.jsdelivr.net/npm/simple-icons@v5/icons/gmail.svg" style="cursor: pointer;" class="iico" id="iemail" title="Click to reveal Bao's email" alt="Contact Bao via email" />
                        </div>
                        <div id="demail"></div>
                        <!-- <a href="resume.pdf" target="_blank" rel="noopener noreferrer" class="resume-button"> -->
                        <a href="full-resume.pdf" target="_blank" rel="noopener noreferrer" class="resume-button">
                            <!-- <img src="https://cdn.jsdelivr.net/npm/simple-icons@v5/icons/filetext.svg" class="iico" alt="PDF icon" /> -->
                            <img src="assets/resume.svg" class="iico" alt="PDF icon" />

                            View Resume
                        </a>
                        <h1>I am currently <strong><span class="job-status open">OPEN</span></strong> for new opportunities</h1>
                    </div>
                </div>
            </div>

            <!-- Popup Modal -->
            <div id="project-modal" class="modal">
                <div class="modal-content">
                    <span class="close">&times;</span>
                    <div id="modal-project-content"></div>
                </div>
            </div>


            <div class="section" id="about">
                <h2>About</h2>
                <p>
                    üëãüèº Hi, I'm <strong>Tran Nguyen Duy Bao</strong>, an <strong>AI / Machine Learning Engineer</strong> based in Vietnam üáªüá≥. 
                    I completed my undergraduate degree in <strong>Computer Science</strong> at <strong>Ton Duc Thang University</strong>. 
                </p>

                <p>
                    I‚Äôm passionate about everything related to <strong>Artificial Intelligence</strong> ‚Äî from <strong>Natural Language Processing (NLP)</strong> to <strong>Computer Vision</strong>. I‚Äôm also experienced with <strong>big data technologies</strong> through academic projects and coursework, including tools like <strong>Apache Spark</strong> and <strong>Kafka</strong> ‚Äî and I love exploring all corners of the AI world. üöÄ
                </p>
                
                <p>
                    Whether it's building smart systems, experimenting with LLMs, or solving real-world problems with deep learning, I'm always excited to learn and grow with the technology.
                </p>
                
                <p>Welcome to my portfolio!</p>

                <h2>SKILLS</h2>


                <div class="skills-container">
                    <div class="tab-buttons">
                        <button class="tab-button active" data-tab="ml-ds">Machine Learning & Data Science</button>
                        <button class="tab-button" data-tab="programming">Programming</button>
                        <button class="tab-button" data-tab="dev-tools">Development Tools</button>
                        <button class="tab-button" data-tab="cloud">Cloud & Deployment</button>
                        <button class="tab-button" data-tab="other">Other</button>
                    </div>
            
                    <div id="ml-ds" class="tab-content active">
                        <div class="skills-section">
                            <!-- <h3>Machine Learning & Data Science</h3> -->
                            <div class="skills">
                                <div class="skill-item"><span>Large Language Models:</span> Transformers (Hugging Face), Langchain, Langgraph, HuggingFace, vLLM</div>
                                <div class="skill-item"><span>LLM APIs:</span> OpenAI API, Google API, AWS API</div>
                                <div class="skill-item"><span>Vector Databases:</span> Pinecone, Qdrant</div>
                                <div class="skill-item"><span>Machine Learning:</span> PyTorch, TensorFlow, Scikit-learn, XGBoost</div>
                                <div class="skill-item"><span>Natural Language Processing:</span> NLTK, SpaCy</div>
                                <div class="skill-item"><span>Computer Vision:</span> OpenCV, YOLO Ultralytics</div>
                                <div class="skill-item"><span>Data Analysis:</span> NumPy, Pandas, Hugging Face Datasets, PySpark</div>
                                <div class="skill-item"><span>Big Data:</span> Apache Spark, Hadoop</div>
                                <div class="skill-item"><span>Data Visualization:</span> Matplotlib, Seaborn, Plotly</div>
                                <!-- <div class="skill-item"><span>Advanced ML:</span> Reinforcement Learning (Stable Baselines 3, Ray RL)</div> -->
                            </div>
                        </div>
                    </div>
            
                    <div id="programming" class="tab-content">
                        <div class="skills-section">
                            <!-- <h3>Programming</h3> -->
                            <div class="skills">
                                <div class="skill-item"><span>Languages:</span> Python, JavaScript (NodeJs, ReactJs)</div>
                                <div class="skill-item"><span>Database:</span>MySQL, Elassandra, MongoDB</div>
                            </div>
                        </div>
                    </div>
            
                    <div id="dev-tools" class="tab-content">
                        <div class="skills-section">
                            <!-- <h3>Development Tools</h3> -->
                            <div class="skills">
                                <div class="skill-item"><span>Version Control:</span> Git, GitHub</div>
                                <div class="skill-item"><span>Autobuild:</span> Github Action, Jenkins</div>
                                <div class="skill-item"><span>Containerization:</span> Docker</div>
                            </div>
                        </div>
                    </div>
            
                    <div id="cloud" class="tab-content">
                        <div class="skills-section">
                            <!-- <h3>Cloud & Deployment</h3> -->
                            <div class="skills">
                                <div class="skill-item"><span>Platforms:</span> Google Cloud Platform, AWS (basic)</div>
                                <!-- <div class="skill-item"><span>MLOps:</span> Weights & Bias, MLflow, Neptune</div> -->
                            </div>
                        </div>
                    </div>
            
                    <div id="other" class="tab-content">
                        <div class="skills-section">
                            <!-- <h3>Other</h3> -->
                            <div class="skills">
                                <!-- <div class="skill-item"><span>IoT:</span> MQTT protocol, Raspberry Pi, Jetson Nano</div>
                                <div class="skill-item"><span>Robotics:</span> ROS (Robot Operating System)</div> -->
                                <div class="skill-item"><span>Operating Systems:</span> MacOS, Ubuntu, Windows</div>
                            </div>
                        </div>
                    </div>
                </div>

            </div>
            

            <div class="section" id="projects">
                <h2>Projects</h2>
                <h3>Real hand-on projects</h3>
                <div class="project-grid" id="imageOverlay">

                    <div class="project-card">
                        <div class="project-preview">
                            <img loading="lazy" src="assets/projects/doctor-assistant/logo.webp" alt="Doctor assistant - Chatbot with AI Agent">
                            <h4>Doctor assistant - Chatbot with AI Agent</h4>
                            <p class="project-brief">Developed an AI agent based chatbot with multimodals, rag with vector database</p>
                            <p class="project-tools">Python, LLM, OpenAI, Azure, GCP, OCR, RAG, Vector DB, Pinecone, Langchain, vLLM, Ollama, PyPDF</p>
                        </div>
                        <button class="view-details-btn">View Details</button>
                        <div class="project-details hidden">
                            <div class="project-info">
                                <p><strong>Date:</strong> 2024 - 2025</p>
                            </div>
                            <p class="project-description">
                                In this project, we developed an AI-powered Doctor Assistant application designed to support real-time, intelligent interaction through natural language and multimodal inputs. The assistant leverages state-of-the-art language models and retrieval techniques to provide medical insights and contextual assistance.
                                
                                <ul>
                                    <li><strong>Conversational AI Agent:</strong> Built with <strong>LangChain</strong> to manage multi-turn conversations, memory, and tool execution for dynamic query handling.</li>
                                    <li><strong>Semantic Search with Pinecone:</strong> Integrated <strong>Pinecone</strong> vector database to perform fast, accurate semantic retrieval from medical documents, PDFs, and patient records.</li>
                                    <li><strong>Multimodal Support:</strong> Enabled the assistant to analyze images (e.g., X-rays, skin conditions), PDFs, and text files to enhance context-aware responses.</li>
                                </ul>

                                Key features:
                                <ul>
                                    <li>Supports natural conversations powered by large language models (LLMs).</li>
                                    <li>Processes and understands uploaded images, PDFs, and text documents.</li>
                                    <li>Performs real-time document embedding and semantic search with Pinecone.</li>
                                    <li>Uses LangChain's agent architecture for flexible tool integration and retrieval-augmented generation (RAG).</li>
                                    <li>Provides accurate and contextual medical support, including document summarization and symptom interpretation.</li>
                                </ul>
                                <figure class="project-figure">
                                    <img class="zoom-cursor" loading="lazy" src="assets/projects/doctor-assistant/diagrams.webp" alt="Doctor Assistant Diagrams">
                                    <figcaption>Chatbot diagrams</figcaption>
                                </figure>
                                <figure class="project-figure">
                                    <img class="zoom-cursor" loading="lazy" src="assets/projects/doctor-assistant/inapp.png" alt="Doctor Assistant App Screenshot - In-app interface with multimodal input support">
                                    <figcaption>In-app interface with multimodal input support</figcaption>
                                </figure>
                                <figure class="project-figure">
                                    <img class="zoom-cursor" loading="lazy" src="assets/projects/doctor-assistant/inapp-history.png" alt="Doctor Assistant App Screenshot - In-app chat history and dialogs">
                                    <figcaption>In-app chat history and dialogs</figcaption>
                                </figure>
                                This project highlights our expertise in LLMs, LangChain agents, and vector-based retrieval while addressing real-world needs in digital healthcare through multimodal interaction and AI.
                            </p>

                            <div class="project-links">
                                <a href="https://play.google.com/store/apps/details?id=com.doctornetwork.doctorassitant&hl=en&pli=1" target="_blank">Android App</a>
                                <a href="https://apps.apple.com/vn/app/doctor-assistant/id6477260207?l=vi" target="_blank">IOS App</a>
                            </div>
                        </div>
                    </div>

                    <div class="project-card">
                        <div class="project-preview">
                            <img loading="lazy" src="assets/projects/spaceone/logo.webp" alt="Spaceone - Big data multimodal summarization and sentiment analysis">
                            <h4>Spaceone - Big data multimodal summarization and sentiment analysis</h4>
                            <p class="project-brief">Utilizing LLM from services with multimodal approach to summarize videos. Sentiment analysis applied on posts comments</p>
                            <p class="project-tools">Python, Kafka, OpenAI, GCP, AWS, NodeJs, Transformer</p>
                        </div>
                        <button class="view-details-btn">View Details</button>
                        <div class="project-details hidden">
                            <div class="project-info">
                                <p><strong>Date:</strong>2024</p>
                            </div>
                            <p class="project-description">
                                <strong>Spaceone</strong> has a multimodal big data pipeline that performs video content summarization and social sentiment analysis at scale. It uses language models, streaming architectures, and fine-tuned NLP techniques to extract insights from both visual/audio and textual data.

                                <ul>
                                    <li><strong>Video Summarization Pipeline:</strong> Built an end-to-end multimodal summarizer for videos. First, <strong>Spleeter</strong> was used to extract clean vocal audio, which was converted into text using a fine-tuned speech-to-text model. This textual content was then passed to <strong>OpenAI‚Äôs LLM</strong> with structured output prompts to generate concise, context-aware summaries.</li>
                                    <li><strong>Sentiment Analysis Module:</strong> Fine-tuned <strong>PhoBERT</strong> weights on domain-specific data (Vietnamese social media posts and comments) to classify sentiment (positive, neutral, negative) with greater contextual accuracy.</li>
                                </ul>

                                Key features:
                                <ul>
                                    <li>Multimodal summarization pipeline combining audio preprocessing, ASR, and LLM-driven summarization.</li>
                                    <li>Fine-tuned transformer-based Vietnamese sentiment classifier for social listening.</li>
                                    <li>Integrated with <strong>Kafka</strong> for scalable message passing and real-time processing of streaming content.</li>
                                    <li>Deployed using a hybrid cloud infrastructure across <strong>GCP</strong> and <strong>AWS</strong> services.</li>
                                    <li>Supports structured summarization output for easier downstream processing and analytics.</li>
                                </ul>
                                <figure class="project-figure">
                                    <img loading="lazy" src="assets/projects/spaceone/comments.png" alt="Spaceone comments statistic chart">
                                    <figcaption>Spaceone comments statistic chart</figcaption>
                                </figure>                                <figure class="project-figure">
                                    <img loading="lazy" src="assets/projects/spaceone/summary.png" alt="Video summary">
                                    <figcaption>Video summary example</figcaption>
                                </figure>
                                <p><strong>What I learned:</strong> This project sharpened my skills in applying large language models to real-world multimodal workflows, fine-tuning pretrained transformers like PhoBERT, and orchestrating streaming data pipelines using Kafka and cloud infrastructure.</p>
                            </p>



                            <div class="project-links">
                                <a href="https://spaceone.vn/" target="_blank">Home page</a>
                                <!-- <a href="https://apps.apple.com/vn/app/doctor-assistant/id6477260207?l=vi" target="_blank">IOS App</a> -->
                            </div>
                        </div>
                    </div>

                    <div class="project-card">
                        <div class="project-preview">
                            <img loading="lazy" src="assets/projects/spooface/logo.webp" alt="Spooface - Face ID with Spoofing detection">
                            <h4>Spooface - Face ID with Spoofing detection</h4>
                            <p class="project-brief">Finetuned YOLOv8 model with an ability to detect spoofing image for checking in, faceid</p>
                            <p class="project-tools">Python, Ultralytics, YOLOv8, OpenCV, DeepFace, Face recognition, Pandas</p>
                        </div>
                        <button class="view-details-btn">View Details</button>
                        <div class="project-details hidden">
                            <div class="project-info">
                                <p><strong>Date:</strong>2024</p>
                            </div>
                            <p class="project-description">
                                In this project, we built a spoofing-aware Face ID system‚Äî<strong>Spooface</strong>‚Äîcapable of verifying real human presence in front of a camera and detecting presentation attacks like photos, screens, and deepfakes during face recognition.

                                <ul>
                                    <li><strong>Finetuned YOLOv8 Model:</strong> Leveraged and retrained <strong>Ultralytics YOLOv8</strong> on a curated spoofing dataset to distinguish between real and spoofed facial inputs.</li>
                                    <li><strong>Spoof Detection Pipeline:</strong> Combined <strong>OpenCV</strong> pre-processing with a multi-step pipeline for live face capture, liveness check, and spoof classification.</li>
                                    <li><strong>Face Recognition Integration:</strong> Integrated <strong>DeepFace</strong> and <strong>face_recognition</strong> libraries to cross-check identity only after passing spoof detection.</li>
                                </ul>

                                Key features:
                                <ul>
                                    <li>Real-time liveness detection to prevent image/video-based spoofing during Face ID authentication.</li>
                                    <li>Custom-trained YOLOv8 model to detect spoofing patterns across multiple environments.</li>
                                    <li>Robust face verification using DeepFace and traditional embedding-based methods.</li>
                                    <li>Lightweight deployment-ready code using Python and OpenCV for edge or kiosk-based check-in systems.</li>
                                    <li>Modular pipeline allowing plug-and-play with other biometric modalities or login systems.</li>
                                </ul>

                                <figure class="project-figure">
                                    <img loading="lazy" src="assets/projects/spooface/both-spoofing.png" alt="Spooface sample detection - real vs spoof">
                                    <figcaption>Real vs. Spoof detection using custom YOLOv8</figcaption>
                                </figure>
                                <figure class="project-figure">
                                    <img loading="lazy" src="assets/projects/spooface/real-spoofing.png" alt="Spooface sample detection - real vs spoof">
                                    <figcaption>In case of only real one detected</figcaption>
                                </figure>
                                The system captures a live frame from the webcam, detects a face using YOLOv8, checks for spoofing features like screen glare or flatness, and only allows identity verification if the input passes the spoofing check.

                                <ul>
                                    <li>üì∑ Capture face via webcam</li>
                                    <li>üß† YOLOv8 detects and classifies real vs spoof</li>
                                    <li>üîç If real, DeepFace performs identity match</li>
                                    <li>üö´ If spoof, access is denied</li>
                                </ul>


                                This project showcases our capabilities in model finetuning, face authentication, and AI-driven fraud detection using computer vision.
                            </p>


                            <div class="project-links">
                                <!-- <a href="https://play.google.com/store/apps/details?id=com.doctornetwork.doctorassitant&hl=en&pli=1" target="_blank">Android App</a>
                                <a href="https://apps.apple.com/vn/app/doctor-assistant/id6477260207?l=vi" target="_blank">IOS App</a> -->
                            </div>
                        </div>
                    </div>

                    <div class="project-card">
                        <div class="project-preview">
                            <img loading="lazy" src="assets/projects/diabetes/logo.png" alt="Diabetes">
                            <h4>Diabetes prediction</h4>
                            <p class="project-brief">Trained a machine learning model on tabular data to predict diabetes status.</p>
                            <p class="project-tools">Python, Pandas, XGBoost, Scikit-learn</p>
                        </div>
                        <button class="view-details-btn">View Details</button>
                        <div class="project-details hidden">
                            <div class="project-info">
                                <p><strong>Date:</strong>2024</p>
                            </div>
                            <p class="project-description">
                                In this project, we developed a regression-based machine learning pipeline to predict users‚Äô blood sugar levels using questionnaire responses and basic medical measurements, with the goal of supporting early-stage diabetes screening in a non-invasive way.

                                <ul>
                                    <li><strong>Data Source & Preprocessing:</strong> Collected data from Google Sheets, resolved 198 mismatched diagnostic records, handled missing values (including 294 missing secondary glucose entries), encoded binary (yes/no) and categorical features, and applied <strong>RobustScaler</strong> for normalization.</li>
                                    <li><strong>Target Transformation:</strong> Due to a left-skewed distribution of glucose values, we applied a log transformation <br><b><i><code>y‚Ä≤ = ln(1 + y)</code></i></b><br> to bring the data closer to a normal distribution and reversed it post-prediction with <br><b><i><code>y = e ∏‚Ä≤ ‚àí 1</code></i></b><br></li>
                                    <li><strong>Handling Imbalanced Data:</strong> Applied <strong>ADASYN</strong> oversampling to balance the training set and address bias toward non-diabetic samples.</li>
                                    <li><strong>Modeling:</strong> Trained and evaluated multiple regression models including <strong>Linear Regression, Ridge, Lasso, ElasticNet, Decision Tree, Random Forest, Gradient Boosting, AdaBoost, SVR, KNN,</strong> and <strong>MLPRegressor</strong>.</li>
                                    <li><strong>Hyperparameter Tuning:</strong> Used <strong>RandomizedSearchCV</strong> for efficient tuning of each model's parameters.</li>
                                    <li><strong>Model Evaluation:</strong> Assessed performance using <strong>MSE, RMSE, MAE,</strong> and <strong>R¬≤</strong> with cross-validation. The best-performing model, <strong>Support Vector Regression (SVR)</strong>, achieved the lowest prediction error (~0.6‚Äì0.7 units) and highest R¬≤ score across test sets.</li>
                                </ul>

                                Key features:
                                <ul>
                                    <li>Regression model trained on questionnaire data and physiological metrics, enabling predictions without lab tests.</li>
                                    <li>Achieved ~5% average prediction error, sufficient for early detection thresholds (typically within ¬±0.5 to 0.8 mmol/L).</li>
                                    <li>Used tabular ML techniques with explainable pipelines suitable for integration into healthcare tools or screening platforms.</li>
                                    <li>Incorporated data visualization and exploratory data analysis (EDA) to guide preprocessing and model selection.</li>
                                </ul>
                                
                                <figure class="project-figure two-images">
                                    <img loading="lazy" src="assets/projects/diabetes/data-skewness.png" alt="data left-skewed">
                                    <img loading="lazy" src="assets/projects/diabetes/data-after-norm.png" alt="data after normalized">
                                    <figcaption><b><i><code>y</code></i></b> column real and after normalized step</figcaption>
                                </figure>
                                <figure class="project-figure">
                                    <img loading="lazy" src="assets/projects/diabetes/model-comparision.png" alt="models comparision">
                                    <figcaption>comparision of models in evaluation phase</figcaption>
                                </figure>

                                <figure class="project-figure">
                                    <img loading="lazy" src="assets/projects/diabetes/result.png" alt="Prediction vs Actual Plot">
                                    <figcaption>Predicted vs. actual blood sugar levels ‚Äì Regression model output</figcaption>
                                </figure>


                                The pipeline processes responses from a health questionnaire, encodes and scales the input, and feeds it into a trained regression model to output a predicted blood sugar level. The result is used to assess diabetes risk.

                                <ul>
                                    <li>üìã Collect user input from health questionnaire</li>
                                    <li>üî¢ Encode binary and continuous features</li>
                                    <li>üß† Predict blood sugar level via regression</li>
                                    <li>‚ö†Ô∏è Map to diabetes risk category</li>
                                </ul>
                                
                                Despite limitations such as missing second glucose test data and class imbalance, the system demonstrated reliable performance and interpretability, highlighting its potential as a scalable tool for accessible diabetes screening.

                                This project highlights my skills in tabular data processing, regression modeling, and AI-based health screening using non-invasive input methods.
                            </p>

                            <div class="project-links">
                                <!-- <a href="https://play.google.com/store/apps/details?id=com.doctornetwork.doctorassitant&hl=en&pli=1" target="_blank">Android App</a>
                                <a href="https://apps.apple.com/vn/app/doctor-assistant/id6477260207?l=vi" target="_blank">IOS App</a> -->
                            </div>
                        </div>
                    </div>
                </div>
                <h3>University projects</h3>
                <div class="project-grid">

                    <div class="project-card">
                        <div class="project-preview">
                            <img loading="lazy" src="assets/projects/traffix/logo.png" alt="Traffix - new approach for google map with public camera">
                            <h4>Traffix - new approach for google map with public camera</h4>
                            <p class="project-brief">Built a traffic-aware navigation app using city cameras and computer vision. Applied YOLOv8 to estimate traffic in real time and optimized routes with A pathfinding.</p>
                            <p class="project-tools">Python, Ultralytics YOLOv8, React Native, OpenCV, Google Maps API</p>
                        </div>
                        <button class="view-details-btn">View Details</button>
                        <div class="project-details hidden">
                            <div class="project-info">
                                <p><strong>Date:</strong> 2024 - 2025</p>
                            </div>
                            <p class="project-description">
                                In this project, we developed <strong>Traffix</strong>, a mobile traffic navigation system that replaces traditional GPS-based routing with real-time visual traffic analysis using public surveillance cameras and computer vision. The goal is to provide more accurate, context-aware routing in congested urban environments using AI.

                                <ul>
                                    <li><strong>Live Camera Integration:</strong> Accessed Vietnamese public traffic camera API to crawl live image feeds across a city district.</li>
                                    <li><strong>Custom YOLOv8 Model:</strong> Labeled and fine-tuned a <strong>YOLOv8</strong> object detection model to count vehicles by type (motorbike, car, bus) in camera snapshots.</li>
                                    <li><strong>A* Pathfinding with Congestion Heuristic:</strong> Built a custom graph where each node represents a public camera. Used A* algorithm with a heuristic weighted by distance and vehicle density (e.g., bus = 6x motorbike).</li>
                                    <li><strong>React Native Frontend:</strong> Created a cross-platform mobile app using <strong>React Native</strong> to display optimal routes and live camera images to users.</li>
                                    <li><strong>Python Backend with Google Maps API:</strong> Implemented a Python API for inference, pathfinding, and integration with <strong>Google Maps</strong> for camera geolocation and visual routing.</li>
                                </ul>

                                Key features:
                                <ul>
                                    <li>Visual real-time traffic analysis using public camera feeds.</li>
                                    <li>AI-powered detection of vehicle types and density via YOLOv8.</li>
                                    <li>Pathfinding system with live congestion heuristics using A*.</li>
                                    <li>Map-based route suggestions augmented with live camera previews.</li>
                                    <li>Focused deployment in a single city district for efficient performance and testing.</li>
                                </ul>

                                <figure class="project-figure">
                                    <img loading="lazy" src="assets/projects/traffix/confusion-matrix.png" alt="Model confusion matrix">
                                    <figcaption>Model confusion matrix</figcaption>
                                </figure>
                                <figure class="project-figure">
                                    <img loading="lazy" src="assets/projects/traffix/PC-curve.png" alt="Model evaluation result PC curve">
                                    <img loading="lazy" src="assets/projects/traffix/RC-curve.png" alt="Model evaluation result RC curve">
                                    <img loading="lazy" src="assets/projects/traffix/PR-curve.jpeg" alt="Model evaluation result PR curve">
                                    <figcaption>Model evaluation result</figcaption>
                                </figure>
                                <figure class="project-figure two-images">
                                    <img loading="lazy" src="assets/projects/traffix/detection-batch1.jpg" alt="Vehicle detection using YOLOv8">
                                    <img loading="lazy" src="assets/projects/traffix/detection-batch2.jpg" alt="Vehicle detection using YOLOv8">
                                    <figcaption>Vehicle detection from public camera snapshots using YOLOv8</figcaption>
                                </figure>
                                <figure class="project-figure two-images">
                                    <img loading="lazy" src="assets/projects/traffix/defaulti-inapp.jpg" alt="Traffix App Screenshot">
                                    <img loading="lazy" src="assets/projects/traffix/route.jpg" alt="Traffix App Route">
                                    <figcaption>Mobile interface showing route and live camera feeds</figcaption>
                                </figure>

                                This project demonstrates our expertise in applied computer vision, route optimization, and integrating public data sources to solve real-world urban mobility challenges.
                            </p>

                            <div class="project-links">
                                <!-- <a href="https://play.google.com/store/apps/details?id=com.doctornetwork.doctorassitant&hl=en&pli=1" target="_blank">Android App</a>
                                <a href="https://apps.apple.com/vn/app/doctor-assistant/id6477260207?l=vi" target="_blank">IOS App</a> -->
                            </div>
                        </div>
                    </div>

                    <div class="project-card">
                        <div class="project-preview">
                            <img loading="lazy" src="assets/projects/stock-lstm/logo.png" alt="Stock LSTM">
                            <h4>Stock Price Forecasting</h4>
                            <p class="project-brief">Analyzed historical stock data and built an LSTM model to forecast future prices using time-series features.</p>
                            <p class="project-tools">Python, Pandas, Seaborn, LSTM, Keras, Plotly</p>
                        </div>
                        <button class="view-details-btn">View Details</button>
                        <div class="project-details hidden">
                            <div class="project-info">
                                <p><strong>Date:</strong> 2023</p>
                            </div>
                            <p class="project-description">
                                This project explored historical stock price data using exploratory data analysis (EDA) techniques and implemented a Long Short-Term Memory (LSTM) neural network for forecasting closing prices based on past trends and volume indicators.

                                <ul>
                                    <li><strong>Data Source & Preprocessing:</strong> Loaded stock data from NSE (Tata), parsed dates, handled sorting/indexing, and checked for nulls. Applied MinMax scaling on selected features (Close, Open, Volume), and used a dedicated scaler for Close price to preserve interpretability.</li>

                                    <li><strong>EDA and Insights:</strong>
                                        <ul>
                                            <li>Visualized Close and Open prices over time</li>
                                            <li>Computed and plotted moving averages (20-day, 50-day) to highlight trend patterns</li>
                                            <li>Analyzed daily returns to identify volatility and potential risk</li>
                                            <li>Built a correlation matrix to understand feature relationships</li>
                                            <li>Used Plotly candlesticks to explore short-term market behavior</li>
                                        </ul>
                                    </li>

                                    <li><strong>Time Series Modeling (LSTM):</strong>
                                        <ul>
                                            <li>Created multivariate sliding windows of past 50 days as input, with the Close price as the target</li>
                                            <li>Built a 2-layer LSTM model with 50 units each, followed by a Dense layer to output predictions</li>
                                            <li>Used Mean Squared Error (MSE) as the loss function for regression</li>
                                            <li>Trained on 80% of the time series data, validated on the remaining 20%</li>
                                            <li>Inverse transformed predictions to recover actual price scale</li>
                                        </ul>
                                    </li>

                                    <li><strong>Mathematical Concepts Applied:</strong>
                                        <ul>
                                            <li>Moving averages to smooth time series and capture trends</li>
                                            <li>Percentage daily returns for measuring momentum and risk</li>
                                            <li>Rolling standard deviation to quantify volatility</li>
                                            <li>Correlation coefficients to assess feature relationships</li>
                                            <li>MinMax scaling for normalization and model convergence</li>
                                            <li>LSTM gating mechanisms to learn temporal dependencies in price movement</li>
                                        </ul>
                                    </li>
                                </ul>

                                <figure class="project-figure">
                                    <img loading="lazy" src="assets/projects/stock-lstm/price-ma.png" alt="Close price with moving averages">
                                    <figcaption>Close price trend with 20-day and 50-day moving averages</figcaption>
                                </figure>

                                <figure class="project-figure two-images">
                                    <img loading="lazy" src="assets/projects/stock-lstm/daily-return.png" alt="Daily returns">
                                    <img loading="lazy" src="assets/projects/stock-lstm/volatility.png" alt="20-D Volatility">
                                    <figcaption>Volatility from EDA</figcaption>
                                </figure>

                                <figure class="project-figure">
                                    <img loading="lazy" src="assets/projects/stock-lstm/eval.png" alt="Prediction vs Actual">
                                    <figcaption>Predicted vs Actual close prices on the validation set</figcaption>
                                </figure>
                                Finally, we got validation result of:
                                <table class="metrics-table">
                                    <thead>
                                        <tr>
                                        <th>Metric</th>
                                        <th>Value</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                        <td>Validation MSE</td>
                                        <td>161.5284</td>
                                        </tr>
                                        <tr>
                                        <td>Validation RMSE</td>
                                        <td>12.7094</td>
                                        </tr>
                                        <tr>
                                        <td>Validation MAE</td>
                                        <td>9.6387</td>
                                        </tr>
                                        <tr>
                                        <td>Validation R¬≤</td>
                                        <td>0.7990</td>
                                        </tr>
                                    </tbody>
                                    </table>

                                This project demonstrates my ability to explore complex time-series data, apply mathematical reasoning, and use deep learning to make informed predictions ‚Äî all within a clear and explainable workflow.

                                <ul>
                                    <li>Analyzed stock time series using domain-relevant features and signals</li>
                                    <li>Used LSTM to capture sequential dependencies in price behavior</li>
                                    <li>Interpreted and visualized results to assess predictive performance</li>
                                </ul>
                            </p>

                            <div class="project-links">
                                <a href="https://data-flair.training/blogs/download-tata-global-beverages-stocks-data/" target="_blank">Data used</a>
                                <a href="https://github.com/Baro1502/stock-price-prediction" target="_blank">GitHub Repo</a>
                            </div>
                        </div>
                    </div>


                </div>
            </div>
    
            </div>


            <div class="section" id="timeline">
                <h2>Timeline</h2>
                <ul class="timeline">
                    <li class="entry">
                        <div class="entry-image">
                            <img loading="lazy" src="assets/mcvgroup.jpeg" alt="MCV Group Logo" />
                        </div>
                        <div class="entry-content">
                            <div class="entry-dot"></div>
                            <div class="entry-header">
                                <h3>AI Engineer</h3>
                                <h4 class="organization">MCV Group</h4>
                                <p class="entry-meta">
                                    <span class="year">2023 - now</span>
                                    <span class="location">Ho Chi Minh city, Vietnam</span>
                                </p>
                            </div>
                            <p>As an AI Engineer, I designed and deployed intelligent systems that handled unstructured and multimodal data to support real-world applications in healthcare and automation.</p>
                                <ul>
                                    <li>Developed and fine-tuned chatbot agents using LLMs and LangChain, enabling natural, multi-turn interactions for medical and customer support use cases.</li>
                                    <li>Built multimedia summarization pipelines that processed and summarized content from images, documents (PDF, Word), and text, improving information accessibility and reducing manual effort.</li>
                                    <li>Created an end-to-end machine learning pipeline for diabetes risk prediction, using structured health data and clinical indicators, achieving strong accuracy in early detection tasks.</li>
                                    <li>Engineered robust data extraction workflows capable of parsing structured and unstructured information from scanned images, PDFs, and document files using OCR and custom logic.</li>
                                    <li>Wrangled complex tabular datasets for training and analytics, applying preprocessing techniques such as feature engineering, normalization, and outlier detection to improve model quality.</li>
                                </ul>

                        </div>
                    </li>
                    <li class="entry">
                        <div class="entry-image">
                            <img loading="lazy" src="assets/tdtu.png" alt="Ton Duc Thang University logo" />
                        </div>
                        <div class="entry-content">
                            <div class="entry-dot"></div>
                            <div class="entry-header">
                                <h3>Bachelor of Technology in Computer Science Engineering</h3>
                                <h4 class="organization">Ton Duc Thang University</h4>
                                <p class="entry-meta">
                                    <span class="year">2021 - 2025</span>
                                    <span class="location">Ho Chi Minh city, Vietnam</span>
                                </p>
                            </div>
                            <p>Bachelor of Technology in Computer Science Engineering with a specialization in Artificial Intelligence at Ton Duc Thang University, Vietnam. It was during this period that I immersed myself in the captivating realms of AI, Machine Learning and Data Science, marking the beginning of my research journey.</p>
                        </div>
                    </li>
                </ul>
            </div>

        </main>
        
        <hr>

        <footer>
            <p>&copy; 2024 Tran Nguyen Duy Bao. All rights reserved.</p>
        </footer>

        <script src="js/main.js"></script>


    </body>
</html>
